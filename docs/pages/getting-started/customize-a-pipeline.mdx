# Customizing Your RAG Pipeline

The R2R library provides flexibility in customizing various aspects of the RAG pipeline to suit your specific needs. You can create custom implementations of the ingestion pipeline, embedding pipeline, RAG pipeline, and evaluation pipeline by subclassing the respective abstract base classes.

## Customize Your Config

Configuring your RAG pipeline is a crucial step in tailoring it to your specific needs. The `config.json` file in your GitHub repository serves as the central point for specifying various settings and providers.

SciPhi currently supports Qdrant and PGVector for vector database providers, OpenAI for embeddings, and LiteLLM for language models. LiteLLM supports most popular providers like OpenAI and Anthropic. Ensure that you provide the appropriate providers and settings according to the R2R documentation.

We explore the different configuration options available below.

### Vector Database Provider

R2R supports multiple vector database providers, including:

- `qdrant`: Integration with Qdrant, a high-performance vector similarity search engine.
- `pgvector`: Integration with PGVector, a vector similarity search extension for PostgreSQL.
- `sciphi`: Managed PGVector database from SciPhi.

To specify the vector database provider, set the `provider` field under `vector_database` in the `config.json` file. Make sure to provide the necessary connection details and credentials for your chosen provider.

### Embedding Provider

R2R supports OpenAI as the embedding provider. To configure the embedding settings, update the `embedding` section in the `config.json` file. Specify the desired embedding model, dimension, and batch size according to your requirements. Currently, only OpenAI is supported, but this can easily be extended by request.

### Language Model Provider

R2R integrates with LiteLLM for language model providers. LiteLLM supports most popular providers like OpenAI, Anthropic, and more. Refer to the [R2R LLM Provider docs](https://r2r-docs.sciphi.ai/integrations/llm-provider) for a detailed explanation on how this support is provided.

At runtime, the user may specify the desired language model provider, model name, and associated parameters like temperature, top_p, top_k, max_tokens_to_sample, and do_stream.

### Evaluation Provider

R2R supports DeepEval and PareaAI as evaluation providers. To configure the evaluation settings, update the `evals` section in the `config.json` file. Specify the evaluation frequency to determine how often the pipeline should be evaluated. These evaluations can be viewed readily in the deployment tab.

### Logging Provider

R2R allows you to configure the logging provider and settings. Update the `logging` section in the `config.json` file to specify the logging provider, log level, logger name, and database name for storing logs. Currently, SQLite, PostgreSQL, and Redis are supported. It is highly recommended to use the default SciPhi logging provider during cloud deployment to reduce latency.

## Custom Pipeline Implementations

### Custom Ingestion Pipeline

To create a custom ingestion pipeline, subclass the `IngestionPipeline` abstract base class and override the necessary methods. For example:

```python
from r2r.pipelines import IngestionPipeline

class CustomIngestionPipeline(IngestionPipeline):
    def process_data(self, entry_type, entry_data):
        # Custom processing logic
        ...
```

Pass your custom ingestion pipeline to the `E2EPipelineFactory.create_pipeline()` method using the `ingestion_pipeline_impl` parameter:

```python
app = E2EPipelineFactory.create_pipeline(
    config=R2RConfig.load_config(),
    ingestion_pipeline_impl=CustomIngestionPipeline,
)
```

### Custom Embedding Pipeline

To create a custom embedding pipeline, subclass the `EmbeddingPipeline` abstract base class and override the necessary methods. For example:

```python
from r2r.pipelines import EmbeddingPipeline

class CustomEmbeddingPipeline(EmbeddingPipeline):
    def transform_chunks(self, chunks, metadatas):
        # Custom chunk transformation logic
        ...
```

Pass your custom embedding pipeline to the `E2EPipelineFactory.create_pipeline()` method using the `embedding_pipeline_impl` parameter:

```python
app = E2EPipelineFactory.create_pipeline(
    config=R2RConfig.load_config(),
    embedding_pipeline_impl=CustomEmbeddingPipeline,
)
```

### Custom RAG Pipeline

To create a custom RAG pipeline, subclass the `RAGPipeline` abstract base class and override the necessary methods. For example:

```python
from r2r.pipelines import RAGPipeline

class CustomRAGPipeline(RAGPipeline):
    def transform_query(self, query):
        # Custom query transformation logic
        ...

    def search(self, transformed_query, filters, limit, *args, **kwargs):
        # Custom document retrieval logic
        ...
```

Pass your custom RAG pipeline to the `E2EPipelineFactory.create_pipeline()` method using the `rag_pipeline_impl` parameter:

```python
app = E2EPipelineFactory.create_pipeline(
    config=R2RConfig.load_config(),
    rag_pipeline_impl=CustomRAGPipeline,
)
```

### Custom Evaluation Pipeline

To create a custom evaluation pipeline, subclass the `EvalPipeline` abstract base class and implement the necessary methods. For example:

```python
from r2r.pipelines import EvalPipeline

class CustomEvalPipeline(EvalPipeline):
    def evaluate(self, query, context, completion):
        # Custom evaluation logic
        ...
```

Pass your custom evaluation pipeline to the `E2EPipelineFactory.create_pipeline()` method using the `eval_pipeline_impl` parameter:

```python
app = E2EPipelineFactory.create_pipeline(
    config=R2RConfig.load_config(),
    eval_pipeline_impl=CustomEvalPipeline,
)
```

## Summary

By customizing the `config.json` file and implementing custom pipeline classes, you can tailor your RAG pipeline to your specific requirements, integrating with different providers, adjusting various settings, and modifying the behavior of the pipelines.

Remember to provide any necessary secrets, such as API keys, during the deployment process. SciPhi ensures that these secrets are encrypted and securely stored.

With these customization options, you have the flexibility to build a RAG pipeline that aligns with your unique use case and enhances the capabilities of your application.
