
During the example pipeline creation a default `config.json` is loaded and passed to the pipeline. It provides settings for the following services:

- Vector Database provider
- LLM settings
- Embedding settings
- Parsing logic
- Evaluation provider
- and more.

The default values for the config are shown below. 

```json
{
  "embedding": {
    "provider": "openai",
    "model": "text-embedding-3-small",
    "dimension": 1536,
    "batch_size": 32
  },
  "evals": {
    "provider": "deepeval",
    "frequency": 1.0
  },
  "language_model": {
    "provider": "litellm"
  },
  "logging_database": {
    "provider": "local",
    "collection_name": "demo_logs",
    "level": "INFO"
  },
  "ingestion":{
    "provider": "local",
    "text_splitter": {
      "type": "recursive_character",
      "chunk_size": 512,
      "chunk_overlap": 20
    }
  },
  "vector_database": {
    "provider": "local",
    "collection_name": "demo_vecs"
  },
  "app": {
    "max_logs": 100,
    "max_file_size_in_mb": 100
  }
}
```
To launch the default pipeline with your own config, you may run with the following

```python

class E2EPipelineFactory:
    ...
    app = E2EPipelineFactory.create_pipeline(
        # override with your own config.json
        config_path="my_config.json",
    )
```
